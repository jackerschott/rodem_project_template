_target_: lightning.pytorch.Trainer

min_epochs: null
max_epochs: 1
enable_progress_bar: true
enable_model_summary: true
log_every_n_steps: 1
default_root_dir: ${io.trainer_root}
ckpt_path: "best"

callbacks:
  - _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${io.checkpoints_path}
    filename: best
    # saves the 'save_top_k' checkpoints with best valid_loss (default save_top_k=1, so only 'best.ckpt')
    monitor: valid_loss
    save_last: true

  - _target_: lightning.pytorch.callbacks.RichModelSummary
    max_depth: 2

  - _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: step

logger:
  - _target_: lightning.pytorch.loggers.wandb.WandbLogger
    log_model: false

    # wandb.init arguments
    name: ${id}
    entity: ${common.logging.wandb_username}
    project: ${common.project_name}
    job_type: "train"
    dir: ${io.logging_dir}
    tags:
      - ${common.stage}
    resume: "auto"
